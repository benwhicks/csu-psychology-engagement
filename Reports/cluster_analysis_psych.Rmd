---
title: "Cluster Assessment for Psychology Engagement Research"
author: Ben Hicks
output: html_document
---

The aim of this document is to explore the options of clustering students in an online course into groups based on their activity data, academic performance, and then both together. There are two subjects analysed (Biopsychology and Social Psychology) and two types of data on each (activity or academic) so we explore 9 possibilities for each clustering method, as we can merge the data or subjects together as an option as well. Of interest is the variance amongst the clustering methods and what is a good choice to provide distinct groups based on the summary activity and academic performance of those groups. 

Example code on R cluster analysis link below[^1] and here[^3].

# 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F, cache = T, fig.width = 8)
#knitr::opts_chunk$set(dev = 'png') - - uncomment to reduce file size
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(GGally))
suppressPackageStartupMessages(library(ggraph))
suppressPackageStartupMessages(library(ggthemes))
suppressPackageStartupMessages(library(ggpubr))
suppressPackageStartupMessages(library(lakit))
suppressPackageStartupMessages(library(dendextend))
suppressPackageStartupMessages(library(ggsci))
suppressPackageStartupMessages(library(factoextra))
suppressPackageStartupMessages(library(cluster))
```

``` {r importing, cache=TRUE}
source(file.path('..','R','psych_functions.R'))
DATDIR <- file.path("~", "Data", "Psychology")
BIOAAFILE <- "aa Biopsychology 201860.csv"
SOCAAFILE <- "aa Social Psychology 201860.csv"
MARKSFILE <- "marks Psychology 201860.csv"
BIOCCFILE <- "cc Biopsychology 201860.csv"
SOCCCFILE <- "cc Social Psychology 201860.csv"
POSTSFILE <- "posts Psychology 201860.csv"

snData <- read_csv(file.path(DATDIR, POSTSFILE), col_types = "cccffn")

# Activity Accumulator Data --------------------------------------
tidy_aa <- function(df) {
  df <- df %>%
    filter(!is.na(id)) %>%
    mutate(forum_bool = str_detect(tolower(data), "discus|thread|forum"),
                                      content = tidyDataField(data),
                                      name = paste0(lastname, ', ', firstname)) %>%
    rename(session = session_id, id = s_id, login_id = id)
  df <- df %>% mutate(forum_bool = if_else(is.na(forum_bool), FALSE, forum_bool))
  return(df)
} 
# --------------------------------------------------------------
aaSoc18 <- read_csv(file.path(DATDIR, SOCAAFILE), col_types = "ffTcccccffcccf")  
aaSoc18 <- tidy_aa(aaSoc18)
aaBio18 <- read_csv(file.path(DATDIR, BIOAAFILE), col_types = "ffTcccccffcccf")
aaBio18 <- tidy_aa(aaBio18)

# Node preparation (i.e. data for each student)

# Mark data
marks18 <- read_csv(file.path(DATDIR, MARKSFILE)) %>%
  mutate(mark = score / possible, id = factor(id)) 
marksSummary18 <- marks18 %>% 
  group_by(subject_name, student, id) %>%
  summarise(avg_grade = mean(mark, na.rm = T)) %>%
  rename(name = student, subject = subject_name)
marksSoc18 <- marksSummary18 %>% filter(subject == "Social Psychology")
marksBio18 <- marksSummary18 %>% filter(subject == "Biopsychology")

# Discussion views from aa -------------------------------------------
discussion_views <- function(df) {
  df %>%
    select(name, subject, forum_bool, data) %>%
    filter(  forum_bool |
           str_detect(tolower(data), "discus|thread|forum")
         ) %>% 
    group_by(subject, name) %>%
    summarise(ForumViews = n()) %>%
    group_by(name) %>%
    summarise(ForumViews = sum(ForumViews))
} 
# ------------------------------------------------------------------
discussionViewsBio <- discussion_views(aaBio18)
discussionViewsSoc <- discussion_views(aaSoc18)

# Other interaction data from aa
aaSummaryBio <- aa_summary_by_user(aaBio18)
aaSummaryBio <- merge(aaSummaryBio, unique(aaBio18 %>% select(id, name)))
aaSummarySoc <- aa_summary_by_user(aaSoc18)
aaSummarySoc <- merge(aaSummarySoc, unique(aaSoc18 %>% select(id, name)))


# Node assembly ----------------------------------------------------------
node_merge_and_make <- function(aaData, marksData, discussionsData) {
  df <- aaData %>% select(-id) %>%
  merge(marksData) %>%
  merge(discussionsData, all.x = T) %>%
  select(ID = id, Name = name, Subject = subject, 
         Grade = avg_grade, Accesses = accesses, 
         mean_clicks_per_access, sd_clicks, 
         median_time_per_access, sd_time, 
         TotalTime = total_time,
         ForumViews) %>%
    mutate(grade_quartile = ntile(Grade, 4), ID = factor(ID))
  if (any(is.na(df$ForumViews))) {
    df[is.na(df$ForumViews),]$ForumViews <- 0
  }
  if (any(is.na(df$Accesses))) {
    df[is.na(df$Accesses),]$Accesses <- 0  
  }
  if (any(is.na(df$TotalTime))) {
    df[is.na(df$TotalTime),]$TotalTime <- 0
  }
  df$Role <- "S"
  return(df)
} # ----------------------------------------------------------------------
nodesBio <- node_merge_and_make(aaSummaryBio, marksBio18, discussionViewsBio)
nodesSoc <- node_merge_and_make(aaSummarySoc, marksSoc18, discussionViewsSoc)

# -----------------------------------------------------------------------------
subject_code_to_name <- function(x) {
  ifelse(str_detect(x, "208|458"), "Biopsychology", "Social Psychology")
} # ---------------------------------------------------------------------------

## ADD ##
allStudentIDs <- unique(marks18$id)
allForumIDs <- unique(snData$msgfrom)
teacherIDs <- setdiff(allForumIDs, allStudentIDs)
teacherNodes <- snData %>% 
  filter(msgfrom %in% teacherIDs) %>% 
  select(Name = poster, ID = msgfrom, Subject = subject) %>% 
  mutate(ID = as.factor(ID), 
         Grade = 0, Accesses = 100, ForumViews = 200, Role = "T", Subject = subject_code_to_name(Subject), 
         TotalTime = as.duration(200000), median_time_per_access = as.duration(2000), sd_time = as.duration(200),
         mean_clicks_per_access = 0, sd_clicks = 0, grade_quartile = 0) %>%
  unique()
teacherNodesBio <- teacherNodes %>% filter(Subject == "Biopsychology")
teacherNodesSoc <- teacherNodes %>% filter(Subject == "Social Psychology")

nodesBio <- rbind(nodesBio, teacherNodesBio)
nodesSoc <- rbind(nodesSoc, teacherNodesSoc)
nodes <- rbind(nodesBio, nodesSoc)
```

``` {r modelling_setup}

make_normed_matrix <- function(df, return_ids = FALSE) {
  ids <- df$ID
  df$median_time_per_access <- as.numeric(as_duration_from_string(df$median_time_per_access))
  df$sd_time <- as.numeric(as_duration_from_string(df$sd_time))
  df <- as.data.frame(sapply(df %>% 
                         filter(Role == "S") %>% 
                         select(-ID, -Name, -Subject, -Role, -grade_quartile), 
                       as.numeric))
  #gq <- df$grade_quartile # does not need to be normed
  df <- scale(df)
  if (return_ids) {
    df$ID <- ids
  }
  #df$grade_quartile <- gq
  return(df)
}

nodeMatrixBio <- make_normed_matrix(nodesBio)
nodeMatrixSoc <- make_normed_matrix(nodesSoc)
nodes <- rbind(nodesBio, nodesSoc) %>% filter(Role == "S")
nodeMatrix <- make_normed_matrix(nodes)

draw_dendrogram <- function(x, dist_metric = "euclidian", method = "ward.D",clust_k = 4) {
  hc <- hclust(dist(x, method = dist_metric), method = method)
  dend <- as.dendrogram(hc)
  clusters <- cutree(hc, clust_k)
  clist <- pal_lancet()(clust_k)
  dend %>%
    set("leaves_col", value = clist, k = clust_k) %>%
    set("labels", "none") %>%
    set("branches_k_color", value = clist, k = clust_k) %>%
    plot(axes = FALSE, leaflab = "none", xlab = paste(dist_metric, "metric, Cluster method:", method))
}

draw_heatmap <- function(x, dist_metric = "euclidian", method = "ward.D", ...) {
  heatmap(x,
          distfun = function(d)dist(d, method = dist_metric),
          hclustfun = function(d)hclust(d, method = method),
          ...)
}

draw_cluster_table <- function(x, dist_metric = "euclidian", method = "ward.D",clust_k = 4) {
  hcAll <- hclust(dist(x, method = D_METRIC), method = METHOD)
  clustersAll <- cutree(hcAll, clust_k)
  nodes$clusterfull <- clustersAll
  clusterAllSummary <- nodes %>% 
  group_by(clusterfull) %>%
  summarise(n = n(), 
            Grade = mean(Grade), 
            Accesses = mean(Accesses), 
            clicks_pa = mean(mean_clicks_per_access),
            sd_clicks = mean(sd_clicks), 
            median_time_pa = as.duration(mean(median_time_per_access)), 
            sd_time = as.duration(mean(sd_time)),
            TotalTime = as.duration(mean(TotalTime)), 
            ForumViews = mean(ForumViews)) %>% 
  rename(cluster = clusterfull)
  knitr::kable(clusterAllSummary)
}

# Analysis of both courses combined
k_all <- 6
k_no_grade <- 4
D_METRIC <- "euclidian"
METHOD <- "ward.D"
```


``` {r lazy_names}
# Making short names for the data sets for convinience
d <- nodeMatrix
dBio <- nodeMatrixBio
dSoc <- nodeMatrixSoc
dAct <- nodeMatrix[, 2:8]
dBioAct <- nodeMatrixBio[, 2:8]
dSocAct <- nodeMatrixSoc[, 2:8]
dGrd <- as.matrix(nodeMatrix[, 1])
dBioGrd <- as.matrix(nodeMatrixBio[, 1])
dSocGrd <- as.matrix(nodeMatrixSoc[, 1])
dlist <- list(d, dBio, dSoc, dAct, dBioAct, dSocAct, dGrd, dBioGrd, dSocGrd)
```

# Ideal number of clusters

We use the gap statistic[^2] to first measure the suggested number of clusters using heirarchical and k-means methods on each of the data sets.

### K-medoids cluster number optimisation - all options

``` {r k_means_k_test, cache = TRUE}
kmp <- function(data, sub, method = "gap_stat") {
  fviz_nbclust(data, cluster::pam, method = method) +
    ggtitle(label = 'Optimal number of clusters, k-medoids', 
            subtitle = sub)   +
     scale_y_continuous(limits = c(0.2, 1.45))
}

ggarrange(kmp(d,    'Both subjects, all data'), 
          kmp(dBio, 'Biopsychology, all data'),
          kmp(dSoc, "Social Psychology, all data"),
          kmp(dAct, 'Both subjects, activity data'),
          kmp(dBioAct, 'Biopsychology, activity data'),
          kmp(dSocAct, "Social Psychology, activity data"),
          kmp(dGrd, "Both subjects, academic data"),
          kmp(dBioGrd, "Biopsychology, academic data"),
          kmp(dSocGrd, "Social Psychology, academic data"),
          nrow = 3, ncol = 3,
          font.label = list(size = 9))
```

Note that the academic clustering is giving much lower results for the gap statistic (nearly half). This is not too suprising as the single variable, *Grade*, although not quite normal is still centrally distributed (see plot below). For the remainder of the report academic clustering methods will be ignored in favour of using quantiles instead.

``` {r qqplot_for_academic_data}
ggarrange(
  ggqqplot(d[,1], title = "Q-Q Plot for Academic Grades"),
  data.frame(Grades = d[,1]) %>% ggplot(aes(x = Grades)) + geom_density() + theme_minimal() + ggtitle("Academic grade distribution")
, nrow = 1, ncol = 2)

shapiro.test(d[ ,1])
```

Also, it is interesting to note that the gap statistic is higher when excluding the academic data. As such it might be prudent to cluster primarily on the activity data and analyse the academic performance as part of that data set. 

Below is a repeat of the graph above with academic data excluded, to better show the variation.

### K-medoids cluster number optimisation

``` {r k_means_k_test2, cache = TRUE}
kmp <- function(data, sub, method = "gap_stat") {
  fviz_nbclust(data, cluster::pam, method = method) +
    ggtitle(label = 'Optimal number of clusters, k-medoids', 
            subtitle = sub)  +
     scale_y_continuous(limits = c(0.9, 1.45))
}

ggarrange(kmp(d,    'Both subjects, all data'), 
          kmp(dBio, 'Biopsychology, all data'),
          kmp(dSoc, "Social Psychology, all data"),
          kmp(dAct, 'Both subjects, activity data'),
          kmp(dBioAct, 'Biopsychology, activity data'),
          kmp(dSocAct, "Social Psychology, activity data"),
          nrow = 2, ncol = 3,
          font.label = list(size = 9))
```

### Hierarchical cluster number optimisation


``` {r heirarchical_k_test, cache = TRUE, fig.width = 8}
hp <- function(data, sub, method = "gap_stat") {
  fviz_nbclust(data, hcut, method = method) +
    ggtitle(label = 'Optimal number of clusters, hierarchical', 
            subtitle = sub)  +
    scale_y_continuous(limits = c(0.9, 1.45))
}

ggarrange(hp(d,    'Both subjects, all data'), 
          hp(dBio, 'Biopsychology, all data'),
          hp(dSoc, "Social Psychology, all data"),
          hp(dAct, 'Both subjects, activity data'),
          hp(dBioAct, 'Biopsychology, activity data'),
          hp(dSocAct, "Social Psychology, activity data"),
          nrow = 2, ncol = 3,
          font.label = list(size = 9))
```

### Hierarchical cluster number optimisation - method comparison

Choosing to fix the data set on both subjects and activity data only, below compares the different metrics for k-medoids and hierarchical clustering. 

``` {r}
h_plot <- function(data, method = "gap_stat") {
  fviz_nbclust(data, hcut, method = method) +
    ggtitle(label = 'Hierarchical') 
}

k_met_plot <- function(data, method = 'gap_stat') {
  fviz_nbclust(data, cluster::pam, method = method) +
    ggtitle("k-medoids")
}

plist <- list(h_plot(dAct, "gap_stat"),
              h_plot(dAct, "silhouette"),
              k_met_plot(dAct, "gap_stat"),
              k_met_plot(dAct, "silhouette"))
ggarrange(plotlist = plist, nrow = 2, ncol = 2)
```


## Visualising the clusters

When we perform the cluster analysis for various values of k and algorithms the results above also pan out.

### K-Medoids clusters

``` {r}
pl <- map(2:6, function(k)fviz_cluster(cluster::pam(dAct, k))+ggtitle(""))
pl[[length(pl) + 1]] <- fviz_nbclust(dAct, cluster::pam, method = "gap_stat") + ggtitle("")
ggarrange(plotlist = pl)
```

### Hierarchical clustering

This uses the *Ward* method for hierarchical clustering. 

``` {r}
p0 <- fviz_nbclust(dAct, hcut, method = "gap_stat") + ggtitle("")
#p1 <- ggdendro::ggdendrogram(hclust(dist(dAct)), method = 'ward.D')
p2 <-  map(2:6, function(k)fviz_cluster(cluster::pam(dAct, k)) + ggtitle(""))
p2[[(length(p2)+1)]] <- p0
ggarrange(plotlist = p2)
```


# Summary statistics of the clusters

It seems worth exploring both the hierarchical clustering and the k-medoids methods. Cluster grouping seems best at 2, but also possible at clusters of 5 if that yields more interesting groupings of the data. All methods and metrics pushed towards the _activity_ data as being the best for distinct clusters and using both subjects data together.

``` {r}
hc2 <- hcut(dAct, 2)
hc5 <- hcut(dAct, 5)
kmed2 <- pam(dAct, 2)
kmed5 <- pam(dAct, 5)

df <- bind_cols(nodes, data.frame(cluster_hc2 = hc2$cluster,
                                  cluster_hc5 = hc5$cluster,
                                  cluster_kmed2 = kmed2$clustering,
                                  cluster_kmed5 = kmed5$clustering))

# feed in grouped by df
cluster_summary_table <- function(x) {
  x %>%
    summarise(n = n(), 
              Biopsych = sum(Subject == "Biopsychology"),
              SocPsych = sum(Subject == "Social Psychology"),
              Grade = mean(Grade),
              Accesses = mean(Accesses),
              clicks_pa = mean(mean_clicks_per_access),
              sd_clicks = mean(sd_clicks),
              median_time_pa = as.duration(mean(median_time_per_access)),
              sd_time = as.duration(mean(sd_time)),
              TotalTime = as.duration(mean(TotalTime)),
              ForumViews = mean(ForumViews)) %>% 
    knitr::kable()
}

df %>% group_by(cluster_hc2) %>% cluster_summary_table()
df %>% group_by(cluster_kmed2) %>% cluster_summary_table()
df %>% group_by(cluster_hc5) %>% cluster_summary_table()
df %>% group_by(cluster_kmed5) %>% cluster_summary_table()

```

## Thoughts

It seems best to choose the k-medoids clustering at 2 and 5, with 5 being possibly more useful for further analysis. 

# Resources

[^1]: R cluster assessment examples: https://www.datanovia.com/en/blog/types-of-clustering-methods-overview-and-quick-start-r-code/ 

[^2]: Gap statistic: https://statweb.stanford.edu/~gwalther/gap 

[^3]: Unsupervised machine learning: http://www.sthda.com/english/wiki/print.php?id=234